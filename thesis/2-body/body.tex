\section{Theory}

This section contains the necessary theory behind inference and probabilistic programs as well as details how the Monad-Bayes library works and a description of the iPMCMC method.

\subsection{Inference on probabilistic programs}
\label{sub:inference_on_probabilistic_programs}

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=1, transform shape]
    \node[draw] (x0) {$x_0$};
    \node[draw, right=of x0] (x1) {$x_1$};
    \node[draw, right=of x1] (x2) {$x_2$};
    \node[right=of x2] (x3) {$\cdots$};

    \node[draw, circle, below=2em of x1] (y1) {$y_1$};
    \node[draw, circle, below=2em of x2] (y2) {$y_2$};

    \path[-stealth]
    (x0) edge node[above] {$f$} (x1)
    (x1) edge  (x2)
    (x2) edge  (x3)
    (x1) edge node[right] {$g$} (y1)
    (x2) edge  (y2);

    \begin{pgfonlayer}{background}
        \filldraw [line width=5mm,join=round,brown!20] (x0.north west) ++ (-2mm,2mm) rectangle
        (y2.south -| x3.east);
    \end{pgfonlayer}
\end{tikzpicture}
\end{center}
\caption{A diagram of a hidden markov process.}
\label{fig:hmm}
\end{figure}

The MCMC methods are based on hidden Markov models. This is a construct of some hidden state $x_t$ evolving by some known process $f(x_t \mid x_{t-1})$ and $\mu(x_0)$ where both functions should be seen as distributions. In other words, the value of $x_t$ is not known, but the underlying process is. In addition some observations $y_t$ \emph{are} known together with their emission process $g(y_t \mid x_t)$. By comparing the measured values $y_t$ with their distribution $g$ and proposed hidden values $x_t$ it is possible to score the proposals and use the scores $w_t$ to find the most likely values.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=1, transform shape,node distance=0.5em]
    \node[minimum width=10em,minimum height=3em,draw] (x1) {program $f$};
    \node[minimum width=10em,draw,below=of x1,inner sep=2mm] (y1) {score $g$};
    \node[minimum width=10em,minimum height=3em,draw,below=of y1] (x2) {program $f$};
    \node[minimum width=10em,draw,below=of x2,inner sep=2mm] (y2) {score $g$};
    \node[minimum width=10em,minimum height=3em,draw,below=of y2] (x3) {program $f$};

    \node[left=of x1] {$x_1$};
    \node[left=of x2] {$x_2$};
    \node[left=of x3] (xx3) {$x_3$};

    \node[right= of y1] (w1) {$w_1$};
    \node[right= of y2] (w2) {$w_2$};

    \node[below=of x3] (dots) {$\vdots$};

    \path[->]
    (y1) edge (w1)
    (y2) edge (w2);

    \begin{pgfonlayer}{background}
        \filldraw [line width=5mm,join=round,brown!20] (x1.north -| w1.east) ++ (0,3mm) rectangle
        (dots.south -| xx3.west);
    \end{pgfonlayer}
\end{tikzpicture}
\end{center}
\caption{A program seen as a hidden Markov model.}
\label{fig:hmmprog}
\end{figure}


In the context of models expressed as probabilistic programs the time aspect is more accurately viewed as the execution of the program. As the program executes random variables are sampled and combined. This corresponds to $f$ above. The program is interrupted at various points by scoring the current execution path, possibly depending on the sampled values. This is the scoring and the method for determining the score is model-dependent on $g$. These scorings separates the programs into parts, the $x_t$'s.

\subsubsection{SMC and CSMC}
\label{ssub:smc_and_csmc}



\begin{figure}[h]
\begin{center}
\begin{tikzpicture}[node distance=1em,scale=1, transform shape,smcnode/.style={circle,draw,inner sep=1mm}]
    \matrix (m) [matrix of nodes,nodes in empty cells, nodes={smcnode}, row sep=2em, column sep=2em]
    {  &  & \node[draw=none] {$\cdots$};  &  \\
       &  & \node[draw=none] {$\cdots$};  &  \\
       &  & \node[draw=none] {$\cdots$};  &  \\
      \node[draw=none] {$\vdots$}; &\node [draw=none]{$\vdots$}; & \node[draw=none] {}; & \node [draw=none]{$\vdots$}; \\
      };

      \path[-stealth]
      (m-3-4) edge ++(0,-3em)
      (m-3-2) edge ++(0,-3em)
      (m-3-1) edge ++(0,-3em)
      (m-2-4) edge (m-3-4)
      (m-2-4) edge (m-3-2)
      (m-2-1) edge (m-3-1)
      (m-1-4) edge (m-2-4)
      (m-1-1) edge (m-2-2)
      (m-1-2) edge (m-2-1);

      \node[left=of m-1-1] {$x_1$};
      \node[left=of m-2-1] {$x_2$};
      \node[left=of m-3-1] {$x_3$};

      \node[above=of m-1-1] {$1$};
      \node[above=of m-1-2] {$2$};
      \node[above=of m-1-4] {$N$};

    \begin{pgfonlayer}{background}
        \filldraw [line width=5mm,join=round,brown!20] (m.north west) ++ (-2em,1em) rectangle
        (m.south east);
    \end{pgfonlayer}
\end{tikzpicture}
\end{center}
\caption{Possible execution of SMC.}
\label{fig:smc}
\end{figure}

In SMC we run the program several times, say N particles, and the execution is interrupted at each scoring and resampling is performed based on the scores $w_{t,1:N}$ according to
\begin{equation}
    x_t^i \sim f(x_t^i \mid x_{t-1}^{a_{t-1}^i})
\end{equation}
where $\Pr(a_{t-1}^i = \ell \mid w_{t-1,1:N}) = w_{t-1,\ell}$. That is, execution is not necessarily continued from where it left off, but an ancestor is chosen at random, weighted on its score. This continues until the program is completed at time $t=T$.

A variant of SMC called conditional sequential Monte Carlo (CSMC) uses an previous trajectory $x'_{1:T}$ to influence the resampling. In the resampling step, the conditional trajectory is not itself resampled. Instead only the other particles are, including from conditional trajectory.

A popular sampler using CSMC is Particle Gibbs (PG). Here several CSMC sweeps are run where the conditional trajectories are chosen from the surviving trajectories of the previous sweep, weighted on final score $w_T^i$.

\subsection{Monad-Bayes}
\label{sec:mbayes}

The Haskell DSL~\cite{mbayes} aims to provide an universal probabilistic
framework in the functional language Haskell. Monad-Bayes supports both
discrete and continuous variables and it's inference performance is comparable to that of
Anglican and Prob-C. The actual library is yet to be released but is already
available\footnote{\url{https://github.com/adscib/monad-bayes}}. The upcoming release
will be based on the \texttt{simple} branch and this is the
version\footnote{Commit \texttt{59a50b1}.} this thesis uses.

The \texttt{simple} branch differs from the implementation discussed in the
paper. The major change is a move from generalized abstract data structures
(GADT's) to only using type classes. The relevant type classes are
\texttt{MonadSample} for monads supporting drawing random values and
\texttt{MonadCond} for monads supporting scoring execution paths. In addition a third type class
\texttt{MonadInfer} exists for monads supporting both.

The \texttt{MonadSample} type class includes methods for drawing values from
several continuous and discreete distributions but the minimal implementation is
a single function
\begin{minted}{Haskell}
class Monad m => MonadSample m
where
  random :: m Double
  \end{minted}
for drawing a value uniformly on the interval $[0,1]$. The second type class
defines a single function
\begin{minted}{Haskell}
class Monad m => MonadCond m
where
  score :: Log Double -> m ()
  \end{minted}
for scoring the execution path. The previously mentioned function
\texttt{condition} in section~\ref{sec:pprog} is defined as
\begin{minted}{Haskell}
condition :: MonadCond m
  => Bool
  -> m ()
condition b = if b
  then score 1 else score 0
\end{minted}
using \texttt{score}. 

Models in Monad-Bayes have the type
\begin{minted}{Haskell}
model :: MonadInfer m => m a
\end{minted}
for a model returning a value of type \texttt{a}. An inference method will transform the model into a sampleable list of values and accumulated scores
\begin{minted}{Haskell}
infer ::
  ( MonadInfer m
  , MonadSample n
  )
  => m a
  -> n [(a, Log Double)]
\end{minted}
so the actual result of the inference may be collected by sampling at the very last step. The library treats inference methods as transformations of distributions that strips it of conditionals (scoring). By using a type constraint there may be choice involved in interpreting the model allowing for flexibility of different inference methods.

There are only two instances of \texttt{MonadSample} directly, \texttt{SamplerIO} and \texttt{SamplerST}. The first sourcing its randomness from the world and the second from it's implicit state. The library defines several monad transformers having instances of \texttt{MonadSample} and \texttt{MonadCond} (possibly depending on the inner monad). A monad
\begin{minted}{Haskell}
newtype Weighted m a =
  Weighted
    (StateT (Log Double) m a)
\end{minted}
for accumulating likelihood with the instance
\begin{minted}{Haskell}
instance Monad m
  => MonadCond (Weighted m)
where
  score w =
    Weighted (modify (* w))
\end{minted}
simply multiplying the observed scores. A more complicated transformer
\begin{minted}{Haskell}
newtype Population m a =
  Population
    (Weighted (ListT m) a)
\end{minted}
is used for a population of particles. The \texttt{ListT} transformer adds non-determinism for running the program several times independently and \texttt{Weighted} provides sampling and scoring.

For sequential methods a transformer
\begin{minted}{Haskell}
newtype Sequential m a =
  Sequential
    (Coroutine (Await ()) m a)
\end{minted}
based on coroutines is provided. It is made an instance of \texttt{MonadCond} by scoring in the underlying monad and then suspending. The inner monad may then be transformed (by for example resampling) before resuming.

\subsection{iPMCMC}

The PG sampler mentioned in section~\ref{ssub:smc_and_csmc} and similar SMC-based samplers suffer from path degeneracy due to the frequent resampling. To acquire good results, a large number of particles is needed which may be infeasible. The iPMCMC sampler aims to alleviate this issue by switching out a CSMC sweep with an independent SMC sweep the next generation for improved mixing.

The iPMCMC sampler runs $M$ nodes indexed $m = 1,\dots,M$ of which $P$ nodes are CSMC and the rest SMC. A conditional node $j$ is identified by $c_j \in \{1,\dots,M\}$. The nodes are run $R$ MCMC iterations. At the first iteration all nodes run SMC since no conditional trajectories are yet available.

Each node $m$ returns returns an estimate of the marginal likelihood
\begin{equation}
    \label{eq:zm}
    \hat Z_m = \prod\limits_{t=1}^T \frac 1 N \sum\limits_{i=1}^N w_{t,m}^i
\end{equation} and its internal trajectories
\begin{equation}
t_m = \{\{(x^i_{t,m},w^i_{t.m})\}_{t=1}^T\}_{i=1}^N
\end{equation}
for use in choosing conditionals. For each MCMC iteration $r$ nodes $1:M \setminus c_{1:P}$ run SMC and nodes $c_{1:P}$ run CSMC using $x'_{1:P}[r-1]$. 

The result is the conditional trajectories $x'_j[r]$ for each conditional node $j$ and MCMC iteration $r$. A function $f(x)$ may be estimated by
\begin{equation}
    \mathbb{E}[f(x)] = \frac 1 {RP} \sum\limits_{r=1}^R \sum\limits_{j=1}^P f(x'_j[r])
\end{equation}
Since the nodes only exchange information between MCMC iterations there is ample room for paralellisation.

\section{Method}

The Monad-Bayes framework contains many components to design models and inference engines.
In particular it already contains an SMC sampler.
However, the sampler does not support providing either the estimated marginal likelihood $\hat Z$ or internal trajectories required to condition the CSMC sampler.
Therefore a custom SMC sampler is required.

Using resampling requires the ability to resume a computation.
One solution is  controlling the randomness and then continue with a specific randomness.
If the random variables are assigned the same values then the result will be the same.
This requires significant bookkeeping and needs a custom sampler to instance the \texttt{MonadSample} type class.
Another solution would be to use coroutines.
Here the calculation may be suspended arbitrarily and resumed at will, simplifying the implementation.
This is what the \texttt{Sequential} monad uses.

The current SMC sampler is based on the \texttt{Sequential} monad and performs a transformation on the inner monad after each step to implement resampling.
The custom SMC sampler would have a complicated inner monad to track both the marginal likelihood and all trajectories.
To avoid a complex and potentially expensive transformation after each step the state is instead kept separate and use the \texttt{Coroutine} monad directly to control the execution.
By using the \texttt{MonadSample} instance of the base monad and yielding the score at each suspension we also have a \texttt{MonadCond} instance.

To simplify the implementation, the models are required to have the same number of scorings in each execution path. This is equivalent to the columns of figure~\ref{fig:smc} always being the same length, i.e. terminating at the same time. The resampling is then greatly simplified by not having to consider the edge case where some particles are already finished.

In summary we represent the model as a coroutine that is advanced to the next scoring, yielding the score $w$. The score is used for resampling and updating the marginal likelihood $\hat Z$ which are kept externally. Finally the trajectories and marginal likelihood are returned.

\subsection{SMC and CSMC implementation}

To simplify the types, several type synonymes are introduced. To represent the model a type
\begin{minted}{Haskell}
type CSMC m a =
  Coroutine
    (Yield (Log Double))
    m a
\end{minted}
is used to add suspension via the \texttt{Coroutine} monad. After each scoring the coroutine suspends and yields the score $w$. The monad \texttt{m} will normally be \texttt{SampleIO}. A \texttt{Trace}, defined as
\begin{minted}{Haskell}
type Trace m a =
  ( Either (CSMC m a) a
  , Log Double)
\end{minted}
is a snaphot of the program execution, paused at a scoring. It contains the rest of the program (or its value) and the accumulated score up to this point.
The traces are collected into a list
\begin{minted}{Haskell}
type Trajectory m a = [Trace m a]
\end{minted}
representing a particle trajectory. The internal state of the CSMC sampler 
\begin{minted}{Haskell}
type SMCState m a =
  ( Vector (Trajectory m a)
  , Log Double)
\end{minted}
hold an array of its particle trajectories and the estimated marginal likelihood.

The signature of the CSMC function is
\begin{minted}{Haskell}
csmc :: MonadSample m
  => Trajectory m a -- ^ x'
  -> Int -- ^ N
  -> CSMC m a -- ^ Model
  -> m (SMCState m a)
\end{minted}
where in addition to the model the number of particles $N$ and the conditional trajectory are supplied. To simplify the implementation, only \texttt{SMCState}'s where either all or no trajectories simultaneously are finished are considered valid. This means the supplied model must have the same number of scorings in every execution path. This constraint is not impossible to remove but was introduced to reduce implementation duration.
The function simply initiates the state and calls a helper function \texttt{csmsHelper}
\begin{minted}{Haskell}
csmcHelper ::
   MonadSample m
=> Maybe (Trajectory m a, Trajectory m a)
-> SMCState m a
-> m (SMCState m a)
\end{minted}
common for both CSMC and SMC. The first argument represents the conditional trajectory split on the current suspension, initially one empty. It is \texttt{Nothing} for SMC denoting no conditional trajectory. The second argument is the carried state, initially only the model with weight and marginal likelihood 1. To advance, a \texttt{stepPop} function is repeatadly applied until the model is finished (end of program).

To step the population of particles with the model a separate function
\begin{minted}{Haskell}
step :: MonadSample m
  => CSMC m a
  -> m (Trace m a)
\end{minted}
advances the model of a single particle, returning the continuation of the program and the score. It is used in the function
\begin{minted}{Haskell}
stepPop :: MonadSample m
  => Maybe (Trajectory m a)
  -> SMCState m a
  -> m (SMCState m a)
\end{minted}
taking the optional trajectory, the current state and returns the new state. Each particle is advanced once and then multinomial resampling is performed. In addition, the marginal likelihood $Z_m$ is updated by multiplying with the mean of the latest scores according to equation~\ref{eq:zm}. The resampling is conditioned on the given trajectory if it exists.

\subsection{iPCMCMC implementation}
\label{sub:ipcmcmc_implementation}

Again, type synonymes are used to simplify the signatures. The result of \texttt{ipmcmc}
\begin{minted}{Haskell}
type IPMCMCResult a = [V.Vector a]
\end{minted}
is a list of the values of the conditional trajectories for each iteration. It is isomorphic to a $R\times P$ matrix. The inner state of the algorithm
\begin{minted}{Haskell}
data IPMCMCState m a = IPMCMCState
  { numnodes :: Int -- M
  , numcond  :: Int -- P
  , nummcmc  :: Int -- R
  , conds    :: V.Vector (Trajectory m a) 
  , result   :: IPMCMCResult a 
  , smcnode  :: m (SMCState m a) 
  , csmcnode ::
    Trajectory m a -> m (SMCState m a) 
  }
\end{minted}
contains the total number of nodes $M$, the number of conditional nodes $P$, remaining MCMC iterations $R$, the chosen conditional trajectories to be used for the next iteration, the accumulated result and two funcitons, aliases for \texttt{smc} and \texttt{csmc} respectively using the supplied model and number of particles $N$.

At the top is the actual sampler
\begin{minted}{Haskell}
ipmcmc :: (MonadFork m, MonadSample m)
  => Int -- N
  -> Int -- M
  -> Int -- R
  -> CSMC m a
  -> m (IPMCMCResult a)
\end{minted}
taking the number of particles per node $N$, the number of nodes $M$ and number of MCMC iterations $R$ in addition to the model. The \texttt{MonadFork} constraint enables concurrent evaluation on the monad. Rainforth et al.~\cite{ipmcmc} found that $P = M/2$ is the optimal number of conditional nodes which is used here. In the first iteration there are no conditional trajectoried available, and unconditional SMC is used for all nodes in the first iteration. Using \texttt{replicateM}, \texttt{forM} and \texttt{forkExec} from the \texttt{Control.Monad.Parallel} package the nodes are evaluated in parallel.

The MCMC step
\begin{minted}{Haskell}
mcmcStep :: MonadSample m
  => V.Vector (SMCState m a) 
  -> V.Vector (SMCState m a)
  -> Int
  -> [Trajectory m a]
  -> m (V.Vector (Trajectory m a))
\end{minted}
takes the results of the conditional and unconditional nodes and two stack-allocated recursion values, \texttt{0} and \texttt{[]}. The former is the first index of the unconditional nodes and the latter the list of sampled conditional trajectories. Returned are the next conitional trajectories. For each conditional node $j$ a representative of the union of $j$ and every conditional node is taken, weighted on $\hat Z_m$ according to

\section{Results}

To evaluate the implemented method it is tested for correctness and performance. Correctness may be demonstated by comparing the results obtained fron the method with the exact posterior distribution. The model is the simple dice model
\begin{minted}{Haskell}
dice_soft :: MonadInfer d => d Int
dice_soft = do
  let die = uniformD [1..6]
  result <- liftM2 (+) die die
  factor (1 / fromIntegral result)
  return result
\end{minted}
rolling two dice and conditioning it with a likelihood that is the reciprocal of the result. The models simplicity allows for calculating the exact posterior via exhaustive enumeration and performant testing. The dissimilarity between the distributions is measured by the standard metric KL divergence~\cite{kl} defined by
\begin{equation}\label{eq:kl}
    D_{\mathrm{KL}} (P \parallel Q) = - \sum\limits_i P(i) \log \frac {Q(i)}{P(i)}
\end{equation}
for the divergence from $Q$ (the truth) to $P$ (the result) and $P(i)$ and $Q(i)$ are the probability of the samples. For a correct method the error should decay according to a power law, giving a straight line in a log-log plot.

First, the custom SMC sampler is compared to the existing SMC sampler of Monad-Bayes. 

For evaluation we choose $M=32$, $N=100$ and $R=1000$ where $M$ and $N$ are the same as the evaulation in the original article and $R$ is chosen to keep the testing time reasonable. The sampler returns a list of samples for each iteration, allowing calculation of the error for any number of iterations $r=1,\dots,R$ by taking the first $r$ elements of the result. For each $r$ the KL divergence is calulated according to equation~\ref{eq:kl}. To stabilize the results, the sampler is run 10 times and for each $r$ a 95\% confidence interval for the error is obtained. The result is given in figure~\ref{fig:corr}.

For performance evaluation the sampler is timed and the error is 

\subsection{Comparisons}
