@article{mbayes,
 author = {\'{S}cibior, Adam and Ghahramani, Zoubin and Gordon, Andrew D.},
 title = {Practical Probabilistic Programming with Monads},
 journal = {SIGPLAN Not.},
 issue_date = {December 2015},
 volume = {50},
 number = {12},
 month = aug,
 year = {2015},
 issn = {0362-1340},
 pages = {165--176},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2887747.2804317},
 doi = {10.1145/2887747.2804317},
 acmid = {2804317},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Bayesian statistics, Haskell, Monte Carlo, monads, probabilistic programming},
}

@inproceedings{ipmcmc,
  title={Interacting Particle Markov Chain Monte Carlo},
  author={Rainforth, Tom and Naesseth, Christian and Lindsten, Fredrik and Paige, Brooks and Vandemeent, Jan-Willem and Doucet, Arnaud and Wood, Frank},
  booktitle={International Conference on Machine Learning},
  pages={2616--2625},
  year={2016}
}

@article {pmcmc,
author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
title = {Particle Markov chain Monte Carlo methods},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {72},
number = {3},
publisher = {Blackwell Publishing Ltd},
issn = {1467-9868},
url = {http://dx.doi.org/10.1111/j.1467-9868.2009.00736.x},
doi = {10.1111/j.1467-9868.2009.00736.x},
pages = {269--342},
keywords = {Bayesian inference, Markov chain Monte Carlo methods, Sequential Monte Carlo methods, State space models},
year = {2010},
}

@article{kl,
	title = {On information and sufficiency},
	volume = {22},
	number = {1},
	journal = {The annals of mathematical statistics},
	author = {Kullback, Solomon and Leibler, Richard A.},
	year = {1951},
	pages = {79--86},
	file = {Snapshot:/home/legopelle/Zotero/storage/58B7VZAS/2236703.html:text/html}
}


@book{barber,
	title = {Bayesian {Reasoning} and {Machine} {Learning}},
	isbn = {978-0-521-51814-7},
	abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Barber, David},
	month = feb,
	year = {2012},
	note = {Google-Books-ID: yxZtddB\_Ob0C},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General}
}


@book{robert,
	title = {Monte {Carlo} {Statistical} {Methods}},
	isbn = {978-1-4757-4145-2},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Robert, Christian and Casella, George},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: 3G2vBQAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / General, Computers / Mathematical \& Statistical Software, Mathematics / Discrete Mathematics, Mathematics / Probability \& Statistics / Stochastic Processes}
}


@incollection{smc,
	series = {Statistics for {Engineering} and {Information} {Science}},
	title = {An {Introduction} to {Sequential} {Monte} {Carlo} {Methods}},
	isbn = {978-1-4419-2887-0 978-1-4757-3437-9},
	url = {https://link.springer.com/chapter/10.1007/978-1-4757-3437-9_1},
	abstract = {Many real-world data analysis tasks involve estimating unknown quantities from some given observations. In most of these applications, prior knowledge about the phenomenon being modelled is available. This knowledge allows us to formulate Bayesian models, that is prior distributions for the unknown quantities and likelihood functions relating these quantities to the observations. Within this setting, all inference on the unknown quantities is based on the posterior distribution obtained from Bayesâ€™ theorem. Often, the observations arrive sequentially in time and one is interested in performing inference on-line. It is therefore necessary to update the posterior distribution as data become available. Examples include tracking an aircraft using radar measurements, estimating a digital communications signal using noisy measurements, or estimating the volatility of financial instruments using stock market data. Computational simplicity in the form of not having to store all the data might also be an additional motivating factor for sequential methods.},
	language = {en},
	urldate = {2018-03-16},
	booktitle = {Sequential {Monte} {Carlo} {Methods} in {Practice}},
	publisher = {Springer, New York, NY},
	author = {Doucet, Arnaud and Freitas, Nando de and Gordon, Neil},
	year = {2001},
	doi = {10.1007/978-1-4757-3437-9_1},
	pages = {3--14},
	file = {Snapshot:/home/legopelle/Zotero/storage/BBHUTUJN/978-1-4757-3437-9_1.html:text/html}
}

@misc{dippl,
  title = {{The Design and Implementation of Probabilistic Programming Languages}},
  author = {Goodman, Noah D and Stuhlm\"{u}ller, Andreas},
  year = {2014},
  howpublished = {\url{http://dippl.org}},
  note = {Accessed: 2018-3-16}
}


@article{bugs,
	title = {A {Language} and {Program} for {Complex} {Bayesian} {Modelling}},
	volume = {43},
	issn = {0039-0526},
	url = {http://www.jstor.org/stable/2348941},
	doi = {10.2307/2348941},
	abstract = {Gibbs sampling has enormous potential for analysing complex data sets. However, routine use of Gibbs sampling has been hampered by the lack of general purpose software for its implementation. Until now all applications have involved writing one-off computer code in low or intermediate level languages such as C or Fortran. We describe some general purpose software that we are currently developing for implementing Gibbs sampling: BUGS (Bayesian inference using Gibbs sampling). The BUGS system comprises three components: first, a natural language for specifying complex models; second, an 'expert system' for deciding appropriate methods for obtaining samples required by the Gibbs sampler: third, a sampling module containing numerical routines to perform the sampling. \$S\$ objects are used for data input and output. BUGS is written in Modula-2 and runs under both DOS and UNIX.},
	number = {1},
	urldate = {2018-03-16},
	journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
	author = {Gilks, W. R. and Thomas, A. and Spiegelhalter, D. J.},
	year = {1994},
	pages = {169--177}
}

@inproceedings{anglican,
  author = {Wood, Frank and van de Meent, Jan Willem and Mansinghka, Vikash},
  booktitle = {Proceedings of the 17th International conference on Artificial Intelligence and Statistics},
  title = {A New Approach to Probabilistic Programming Inference},
  pages = {1024-1032},
  year = {2014}
}

